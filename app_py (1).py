# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qAFUfLlMB_wx7m6bBE-wIC-wRyhqdDBT
"""

!pip install streamlit

# Commented out IPython magic to ensure Python compatibility.
# 
# %%writefile app.py
# 
# import streamlit as st
# import joblib
# import pandas as pd
# import numpy as np
# 
# st.title(" Customer Churn Prediction App")
# 
# # Load the scaler and model
# try:
#     scaler = joblib.load('scaler.pkl')
#     model = joblib.load('churn_model.pkl')
# except FileNotFoundError:
#     st.error("Error: scaler.pkl or churn_model.pkl not found. Please make sure to run the code to save the scaler and model first.")
#     st.stop()
# 
# 
# st.divider()
# 
# st.write("please enter the values and hit the predict button for getting a prediction.")
# 
# st.divider()
# 
# 
# # Input fields
# age = st.number_input("Age", min_value=18, max_value=100)
# tenure = st.number_input("Tenure (Months)", min_value=0)
# usage = st.number_input("Usage Frequency", min_value=0)
# spend = st.number_input("Total Spend")
# calls = st.number_input("Support Calls", min_value=0)
# delay = st.number_input("Payment Delay", min_value=0)
# interaction = st.number_input("Last Interaction (Days Ago)", min_value=0)
# 
# if st.button("Predict Churn"):
#     new_data = pd.DataFrame([{
#         'Age': age, 'Tenure': tenure, 'Usage Frequency': usage,
#         'Total Spend': spend, 'Support Calls': calls,
#         'Payment Delay': delay, 'Last Interaction': interaction
#     }])
# 
#     new_data_scaled = scaler.transform(new_data)
#     prediction = model.predict(new_data_scaled)
# 
#     st.success("Prediction: " + ("This is customer is likely to Churn" if prediction[0] == 1 else "This customer is Likely to Stay"))

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/your_folder_name
!ls

#!streamlit run app.py & npx localtunnel --port 8501